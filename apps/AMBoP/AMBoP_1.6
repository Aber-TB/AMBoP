#!/bin/bash -l

now=$(date)
CONFIG_DIR=$(pwd)
AMBOP_DIR=$(echo ${0} | sed 's/\/AMBoP_1.6//')
#This is the header that will print out the welcome message. It checks for adequate input and if not, prints usage. If a user provides "example.config" an example config file will be printed to screen.
if [ "$#" -eq 0 ]; then
    echo -e "\e[1;35m     ___    __  _______        ____\n   /   |  /  |/  / __ )____  / __ \\n  / /| | / /|_/ / __  / __ \/ /_/ /\n / ___ |/ /  / / /_/ / /_/ / ____/ \n/_/  |_/_/  /_/_____/\____/_/      \e[0m"
    echo "Aberystwyth M. bovis Pipeline (AMBoP)."
    echo "Version 1.6"
    echo "GitHub: https://github.com/Aber-TB/AMBoP"
    echo "Technical Help: jess@friedersdorff.com | nicholas@dimonaco.co.uk"
    echo "Current Time: $now"
    echo "Takes raw sequence data, finds SNPs, outputs functional information about these SNPs and builds trees."
    echo ""
    echo "Usage:"
    echo "AMBoP <file.config | example.config>"
    echo "Use '&> <log.file>' to produce runtime logfile"
    echo "Check and edit the AMBoP example config file and specify this file when executing AMBoP."
    exit
elif [ "$1" = "example.config" ]; then
    cat ${AMBOP_DIR}/example.config;
    exit
fi

#This is the start of the output file:
echo -e "    ___    __  _______        ____\n   /   |  /  |/  / __ )____  / __ \\n  / /| | / /|_/ / __  / __ \/ /_/ /\n / ___ |/ /  / / /_/ / /_/ / ____/ \n/_/  |_/_/  /_/_____/\____/_/      "
echo -e "Current Time: $now"
echo -e " This is the output file for running the Aberystwyth M. bovis Pipeline (AMBoP)."
echo -e " Output is colour and symbol coded for easy readability. To see check points, use grep \"[%]\" your.output. To see errors, use grep \"[!]\" your.output. To see advice about what to do next, use grep \"[?]\" your.output. To see some extra information about sample progress, use grep \"[@]\" your.output."
echo -e "\e[1;31m Red text means an error has occured or something needs checking or fixing. These lines start with [!].\e[0m"
echo -e "\e[1;33m Yellow text shows which stage has started. These lines start with [%].\e[0m"
echo -e "\e[1;34m Blue text shows which stage has completed. These lines start with [%]. \e[0m"
echo -e "\e[1;35m Purple text shows some extra information, often just saying that files are present if this is being rerun. These lines start with [@].\e[0m"
echo -e "\e[1;36m Cyan text shows advice about what to do next. These lines start with [?]. \e[0m"
echo -e "\e[1;32m Green text may be used to highlight sample. \e[0m"
echo -e " White text is output from tools or programs, which may or may not have colours too.\n\n\n"

echo -e " Config File Used: $1"  


#Activate environment or if this fails, create the conda environment from the yaml file
#source activate AMBoP_Conda_env || conda env create --file AMBoP_Conda_env.yml; source activate AMBoP_Conda_env || echo -e "\e[1;31m [!] Conda cannot activate the environment, exitting. \e[0m" ; exit 

#echo -e "\e[1;35m [@]Conda environment loaded.\e[0m"

#Source the config file supplied so that the variables are available:
source $1
#Add aux_tools to path
export PATH=$(echo ${AUX_TOOLS}):$PATH

echo -e "\e[1;35m [@] Path to output set to: ${MYPATH}\e[0m"
echo -e "\e[1;35m [@] Path to raw data files set to: ${DATAPATH}\e[0m"
echo -e "\e[1;35m [@] Path to aux_tools-0.2 set to: ${AUX_TOOLS}\e[0m"
echo -e "\e[1;35m [@] Forward read pattern is ${FORWARDPATTERN} and reverse read pattern is ${REVERSEPATTERN}.\e[0m"
echo -e "\e[1;35m [@] Path to reference genome file set to: ${REFPATH}\e[0m"
echo -e "\e[1;35m [@] Unique file names set to: ${UNIQ}\e[0m"
echo -e "\e[1;35m [@] Number of threads set to: ${THREADS}\e[0m"
echo -e "\e[1;35m [@] $(date)\e[0m"

echo -e "\e[1;33m [%] Starting... \e[0m"

#Check whether directories exist, if not, make some directories 

[ -d ${MYPATH}/trimmed_reads ] && echo -e "\e[1;35m [@] Directory trimmed_reads exists.\e[0m" || mkdir ${MYPATH}/trimmed_reads #for the trimmed reads
[ -d ${MYPATH}/bams ] && echo -e "\e[1;35m [@] Directory bams exists.\e[0m" || mkdir ${MYPATH}/bams  #for the bams after alignment to genome
[ -d ${MYPATH}/passed_files ] && echo -e "\e[1;35m [@] Directory passed_files exists.\e[0m" || mkdir ${MYPATH}/passed_files #for bam files that pass the coverage filter.
[ -d ${MYPATH}/variants ] && echo -e "\e[1;35m [@] Directory variants exists.\e[0m" || mkdir ${MYPATH}/variants #for the vcf files
[ -d ${MYPATH}/variants/functional ] && echo -e "\e[1;35m [@] Directory functional exists.\e[0m" || mkdir ${MYPATH}/variants/functional #for those variants involved in functional genes
[ -d ${MYPATH}/fasta_aln ] && echo -e "\e[1;35m [@] Directory fasta_aln exists.\e[0m" || mkdir ${MYPATH}/fasta_aln #for the fastas and the aligned files
[ -d ${MYPATH}/tree ] && echo -e "\e[1;35m [@] Directory tree exists.\e[0m" || mkdir ${MYPATH}/tree  #for the phylogenetic tree files
[ -d ${MYPATH}/fastqc ] && echo -e "\e[1;35m [@] Directory fastqc exists.\e[0m" || mkdir ${MYPATH}/fastqc  #for the fastqc checking files
[ -d ${MYPATH}/fastqc/pre_trimming ] && echo -e "\e[1;35m [@] Directory fastqc/pre_trimming exists.\e[0m" || mkdir ${MYPATH}/fastqc/pre_trimming  #for the fastqc checking files
[ -d ${MYPATH}/fastqc/post_trimming ] && echo -e "\e[1;35m [@] Directory fastqc/post_trimming exists.\e[0m" || mkdir ${MYPATH}/fastqc/post_trimming  #for the fastqc checking files
[ -d ${MYPATH}/final_files ] &&  echo -e "\e[1;35m [@] Directory final_files exists. \e[0m" || mkdir ${MYPATH}/final_files #for the final files to be easily accessible.


#check $FORWARDPATTERN files exist:
if [ $(ls -l ${DATAPATH}/*${FORWARDPATTERN} 2>/dev/null | awk '{if ($5 != 0) print $9}' | wc -l) -lt 1 ]; then
    echo -e "\e[1;31m [!] $FORWARDPATTERN files not found, check pattern provided in config file.\e[0m"; 
    exit ;
else
    echo -e "\e[1;35m [@] $(ls ${DATAPATH}/*${FORWARDPATTERN} | wc -l) forward files found.\e[0m";
fi

#Check $REVERSEPATTERN files exist:
if [ $(ls -l ${DATAPATH}/*${REVERSEPATTERN} 2>/dev/null | awk '{if ($5 != 0) print $9}' | wc -l) -lt 1 ]; then
    echo -e "\e[1;31m [!] $REVERSEPATTERN files not found, check pattern provided in config file.\e[0m";
    exit ;
else
    echo -e "\e[1;35m [@] $(ls ${DATAPATH}/*${REVERSEPATTERN} | wc -l) reverse files found.\e[0m"
    fi

###############
# Perform FASTQC on raw reads, then Multiqc:

if [ ${FASTQC} == true ]; then

    echo -e "\e[1;33m [%] Starting quality checking of untrimmed reads. \e[0m"
    for seq_file in $(ls ${DATAPATH}/*${FORWARDPATTERN}); do
	sample_name=$(echo ${seq_file} | awk -F "/" '{print $NF}' | sed 's/\.fastq\.gz//')

	#Check forward read fastqc files exist:
	if [ -s ${MYPATH}/fastqc/pre_trimming/${sample_name}_fastqc.zip ]; then
	    #if found:
	    echo -e "\e[1;35m [@] Quality report for ${sample_name} already produced.\e[0m"
	else
	    #run fastqc on the file
            fastqc -o ${MYPATH}/fastqc/pre_trimming \
	           -f fastq ${seq_file}
	fi
    done

    for rev_seq_file in $(ls ${DATAPATH}/*${REVERSEPATTERN}); do
	sample_name=$(echo ${rev_seq_file} | awk -F "/" '{print $NF}' | sed 's/\.fastq\.gz//')

	#Check reverse read fastqc files exist
	if [ -s ${MYPATH}/fastqc/pre_trimming/${sample_name}_fastqc.zip ]; then
	    #if found:
            echo -e "\e[1;35m [@] Quality report for ${sample_name} already produced.\e[0m"
	else
	    #run fastqc on the file 
            fastqc -o ${MYPATH}/fastqc/pre_trimming \
		   -f fastq ${rev_seq_file}
	fi
    done
    if [ -s ${MYPATH}/${UNIQ}_multiqc.html ]; then
	echo -e "\e[1;35m [@] Read quality report with multiqc has already produced for all of your samples; check ${MYPATH}/${UNIQ}_multiqc.html\e[0m"
    else
	multiqc ${MYPATH}/fastqc/pre_trimming/ --outdir ${MYPATH} --filename ${UNIQ}_multiqc
	echo -e "\e[1;34m [%] Finished quality checking of untrimmed reads. Check ${MYPATH}/${UNIQ}_multiqc.html for stats on raw read quality.\e[0m"
    fi
       
    if [ ${TRIM_FASTQC} == false ]; then
	exit
    fi
fi


###############
#trim data using Trimmomatic v0.39 with settings removing universal Illumina adaptors, minimum length of 50, sliding window size 3 with average score of 20 and average quality of 20.

echo -e "\e[1;33m [%] Beginning read trimming. \e[0m"

cd ${MYPATH}/trimmed_reads

ln -s ${ADAPTERS} 2>/dev/null #symbolically link the adapter fasta file so Trimmomatic can find it.

for i in $(ls ${DATAPATH}/*${FORWARDPATTERN}); do
    file=$(echo ${i} | awk -F "/" '{print $NF}' | sed  "s/_R1/;/" $NF | sed "s/_R2/;/" $NF  | cut -d ";" -f1);    
    #Do a quick check to see if there are any non-empty trim-paired files, like if the script has been run before to save time overwriting.
    if [ -s ${MYPATH}/trimmed_reads/${file}_1_trim_paired.fastq.gz ] ; then 
	echo -e "\e[1;35m [@] ${file} already trimmed.\e[0m"; 
    else  
    trimmomatic PE -threads ${THREADS} \
        ${DATAPATH}/${file}*${FORWARDPATTERN} \
        ${DATAPATH}/${file}*${REVERSEPATTERN} \
        ${file}_1_trim_paired.fastq.gz \
        ${file}_1_trim_unpaired.fastq.gz \
        ${file}_2_trim_paired.fastq.gz \
        ${file}_2_trim_unpaired.fastq.gz \
        ${ILLUMINACLIP} \
        ${SLIDINGWINDOW} \
        ${MINLEN} \
        ${AVGQUAL} ||
    exit; 
    echo -e "\e[1;35m [@] Finished trimming sample\e[0m \e[0;32m ${file} \e[0m";
    fi;
done

echo -e "\e[1;33m [%] Removing unecessary unpaired Trimmomatic files...\e[0m"
rm -rf *_1_trim_unpaired.fastq.gz *_2_trim_unpaired.fastq.gz

echo -e "\e[1;34m [%] Trimmomatic finished. \e[0m"

###############
# Perform FASTQC on trimmed data.

if [ ${TRIM_FASTQC} == true ] ; then

    echo -e "\e[1;33m [%] Starting quality check of trimmed reads. \e[0m"
    
    for trimmed_seq_file in $(ls ${MYPATH}/trimmed_reads/*trim_paired.fastq.gz); do
     trimmed_sample_name=$(echo ${trimmed_seq_file} | awk -F "/" '{print $NF}' | sed 's/\.fastq\.gz//')
	#Check forward read fastqc files exist:
	if [ -s ${MYPATH}/fastqc/post_trimming/${trimmed_sample_name}_fastqc.zip ]; then
	    #if found:
	    echo -e "\e[1;35m [@] Quality report for ${trimmed_sample_name} already produced.\e[0m"
	else
	    #run fastqc on the file
	    fastqc -o ${MYPATH}/fastqc/post_trimming \
	    -f fastq ${trimmed_seq_file}
	fi
    done
    
    if [ -s ${MYPATH}/${UNIQ}_trimmed_multiqc.html ]; then
	echo -e "\e[1;35m [@] Read quality report with multiqc has already produced for all of your trimmed samples; check ${MYPATH}/${UNIQ}_trimmed_multiqc.html.\e[0m"
    else
	multiqc ${MYPATH}/fastqc/post_trimming/ --outdir ${MYPATH} --filename ${UNIQ}_trimmed_multiqc
	echo -e "\e[1;34m [%] Finished quality checking of trimmed reads. Check ${MYPATH}/${UNIQ}_trimmed_multiqc.html for stats on raw read quality.\e[0m"
    fi

    exit
fi


###############
#Align paired end reads to reference genome and use Samtools to handle file and keep only primary alignments.

echo -e "\e[1;33m [%] Aligning samples to reference genome. \e[0m"



#Check whether index files are present, if not create them:
if [ -s ${REFPATH}.amb ] && [ -s ${REFPATH}.ann ] && [ -s ${REFPATH}.bwt ] && [ -s ${REFPATH}.pac ] && [ -s ${REFPATH}.sa ]; then
    echo -e "\e[1;35m [@] Reference genome index files found. \e[0m"; 
else 
    echo -e "\e[1;35m [@] Some reference genome index files may be missing, rerunning bwa index command\e[0m"; 
    bwa index ${REFPATH} || { echo -e "\e[1;31m [!] BWA indexing failed.\e[0m" ; exit ; }; 
fi

cd ${MYPATH}/bams

#Check whether there are any trimmed files:
if [ $(ls -l ../trimmed_reads/*_1_trim_paired.fastq.gz 2>/dev/null | awk '{if ($5 != 0) print $9}' | wc -l) -lt 1 ]; then
    echo -e "\e[1;31m [!] No trimmed read files found.\e[0m"; 
    exit ;
fi


for i in $(ls ../trimmed_reads/*_1_trim_paired.fastq.gz); do 
    file=$(echo ${i} | awk -F "/" '{print $NF}' | sed  "s/_1_trim/;/" $NF | cut -d ";" -f1);    
    if [ -s ${MYPATH}/bams/${file}_sorted.bam ]; then  
	echo -e "\e[1;35m [@] ${file} has already been aligned. The output file named ${file}_sorted.bam may be present, but this is removed in later steps of the pipeline so may not be - this is expected.\e[0m"; 
    elif [ -s ${MYPATH}/bams/${file}_sorted_nodups.bam ]; then 
	echo -e "\e[1;35m [@] ${file} has already been aligned and deduplicated, resulting file can be found as ${file}_sorted_nodups.bam.\e[0m"
    
    else 
	{ bwa mem -t ${BWA_THREADS} ${REFPATH} \
              ../trimmed_reads/${file}_1_trim_paired.fastq.gz \
              ../trimmed_reads/${file}_2_trim_paired.fastq.gz  || echo -e "\e[1;31mBWA alignment failed.\e[0m"; exit;
	}|
	{ samtools view -F 2308 -b || echo -e "\e[1;31mSamtools found an error aligned files.\e[0m"; exit ;
	}|
	{ samtools sort > ${file}_sorted.bam || echo -e "\e[1;31mSamtools failed to sort the aligned files.\e[0m"; exit;
	};
    echo -e "\e[1;34m Finished sample\e[0m \e[0;32m ${file} \e[0m";
    fi;
done 


echo -e "\e[1;34m [%] BWA aligning finished. \e[0m"

###############
#Do some Samtools file handling if there are no files ending in *nodups.bam:

echo -e "\e[1;33m [%] Starting Samtools file handling. \e[0m"

#Check is duplicates have already been removed, otherwise remove duplicates:
if [ $(ls -l *sorted_nodups.bam 2>/dev/null | awk '{if ($5 != 0) print $9}' | wc -l) -gt 0 ]; then 
     echo -e "\e[1;31m [!] Bam files may have already been deduplicated, check these files.\e[0m"
     echo -e "\e[1;35m [@] Skipping Samtools filehandling \e[0m";
else
    for i in $(ls *_sorted.bam); do 
	echo -e "\e[1;35m [@] Removing duplicates in sample\e[0m \e[0;32m ${i} \e[0m"
	name=$(echo $i | sed  "s/_sorted.bam/;/" | cut -d ";" -f1);
	samtools rmdup -S ${i} ${name}_sorted_nodups.bam || exit;
    done;
#sort the bams:
    for i in $(ls *_sorted_nodups.bam); do
	file=$(echo ${i} | awk -F "/" '{print $NF}' | sed  "s/_1_trim/;/" $NF | cut -d ";" -f1);    
	echo -e "\e[1;35m [@] Indexing sample\e[0m \e[0;32m ${file} \e[0m";
	samtools index ${i} || exit; 
    done;

    #Save space, remove old bams: 
    echo -e "\e[1;33m [%] Removing unecessary sorted bam files.\e[0m";
    rm -f *_sorted.bam;
    echo -e "\e[1;34m [%] Finished Samtools file handling. \e[0m";
fi

###############
#Check read mapping.

echo -e "\e[1;33m [%] Starting read mapping checks. \e[0m"

#Calculate reference genome coverage for each sample: - Only checks if file exists - not good for crash
if [ -f bamfile_coverage.list ]; then 
   echo -e "\e[1;35m [@]  Coverage already calculated: \e[0m";
   cat bamfile_coverage.list;
else
   for i in $(ls *_sorted_nodups.bam); do 
       calculate_genomecov.sh ${i} || exit; 
   done > bamfile_coverage.list;
   echo -e "\e[0;32m Bam file coverage: \e[0m";
   cat bamfile_coverage.list;
fi


# TODO(JF): Create notification for user of samples being dumped.

#Decide whether coverage is enough to continue analysis for each sample. Only run if 'passed_files' is not already empty:
if [ $(ls ${MYPATH}/passed_files/ 2>/dev/null | wc -l) -gt 0 ]; then 
    echo -e "\n\e[1;31m [!] Passed_files directory exists and is not empty. Check files are correct by comparing with files listed bamfile_coverage.list or remove and rerun. \e[0m";
else
    for i in $(ls *_sorted_nodups.bam); do 
	select_files.sh ${i} 1 ${MYPATH}/passed_files || exit; 
    done;
fi


echo -e "\e[1;34m [%] Finished read mapping checks. \e[0m"


##################

echo -e "\e[1;33m [%] Starting variant calling. \e[0m"



cd ${MYPATH}/passed_files


for i in $(ls *_sorted_nodups.bam); do 
    name=$(echo ${i} | sed  "s/_sorted_nodups.bam/;/" | cut -d ";" -f1);  
    if [ -s ${MYPATH}/variants/${name}.vcf ]; then
        echo -e "\e[1;35m [@] ${name} vcf has already been created. \e[0m";
    elif [ -s ${MYPATH}/variants/${name}_filtered.vcf.gz ]; then
	echo -e "\e[1;35m [@] ${name} vcf has already been filtered and compressed. Skipping calling variants again.\e[0m";
    else
	{ bcftools mpileup -d 1000 ${i} --fasta-ref ${REFPATH} || echo -e "\e[1;31m [!] bcftools failed to run mpileup command.\e[0m"; exit ;
	} | 
            bcftools call --ploidy 1 --multiallelic-caller --output-type v --variants-only -V indels --output $MYPATH/variants/${name}.vcf || exit;  
	echo -e "\e[1;35m [@] Finished variant calling for sample\e[0m \e[0;32m ${name} \e[0m";
    fi
done

echo -e "\e[1;34m [%] Finished variant calling. \e[0m"

###################
echo -e "\e[1;33m [%] Starting vcf file filtering. \e[0m"

cd ${MYPATH}/variants

for i in $(ls ${MYPATH}/passed_files/*_sorted_nodups.bam); do
    name=$(echo ${i} |  awk -F "/" '{print $NF}' | sed 's/_sorted_nodups.bam/;/' | cut -d ";" -f1);
    if [ -s ${MYPATH}/variants/${name}_filtered.vcf ]; then
	echo -e "\e[1;35m [@] ${name} vcf has already been filtered. \e[0m";
    elif [ -s ${MYPATH}/variants/${name}_filtered.vcf.gz ]; then
	echo -e "\e[1;35m [@] ${name} vcf has already been filtered and compressed.\e[0m"
    else
	bcftools filter -i "DP>=${DP} & MQ>=${MQ} & DP4[2]>=${DP4F} & DP4[3]>=${DP4R} & (DP4[2]+DP4[3])/(DP4[0]+DP4[1]+DP4[2]+DP4[3])>=${SUPPORT}" ${name}.vcf |
	    ${AUX_TOOLS}/variantpositionfiltering.py ${VAR_POS_NUM} |
	    ${AUX_TOOLS}/exclude_regions.py ${REGIONS}  > ${name}_filtered.vcf;
	echo -e "\e[1;35m [@] Finished filtering variants for sample\e[0m \e[0;32m ${name} \e[0m";
    fi;
done

echo -e "\e[1;34m [%] Finished filtering vcf files. \e[0m"

###################

#Then compress the files, index and then merge the samples into one vcf file.
#BCFTools requires the vcfs to be compressed into .gz files before processing. It also will not take more than 1021 files as input as once for merging, therefore
#the files have to be put into subsets and merged, then these subset files are merged into one.

echo -e "\e[1;33m [%] Starting filtered vcf file compression and merging. \e[0m"

for i in $(ls ${MYPATH}/passed_files/*_sorted_nodups.bam); do
    sample=$(echo ${i} | awk -F "/" '{print $NF}' | sed 's/_sorted_nodups.bam/;/' | cut -d ";" -f1)
    if [ -s ${MYPATH}/variants/${sample}_filtered.vcf ]; then
	bgzip ${sample}_filtered.vcf || { echo -e "\e[1;31mFailed to compress vcf file.\e[0m"; exit ; };
    elif [ -f ${MYPATH}/variants/${sample}_filtered.vcf.gz ]; then
	echo -e "\e[1;35m [@] ${sample} already compressed.\e[0m";
    else
	echo -e "\e[1;31m [!] ${sample} - no vcf or compressed vcf found, check variant calling completed correctly.\e[0m";
	exit;
    fi;
done

for i in *_filtered.vcf.gz; do
    if [ -f ${i}.csi ]; then
	echo -e "\e[1;35m [@] ${i} already indexed \e[0m";
    else
	bcftools index ${i} || { echo -e "\e[1;31m [!] Failed to index compressed vcf file.\e[0m"; exit; } ;
    fi;
done


[ -f ${UNIQ}_filtered_merged.vcf.gz ] && echo -e "\e[1;35m [@] ${UNIQ}_merged.vcf.gz already exists\e[0m" || {
	ls *_filtered.vcf.gz | split -l 500 - subset_vcfs;
	for i in $(ls subset_vcf*); do
	    bcftools merge -l ${i} -O z -o merged_${i}.vcf.gz;
	    bcftools index merged_${i}.vcf.gz;
	done;
	ls merged_*.vcf.gz > merged_subsets.list
	bcftools merge -l merged_subsets.list -O z -o ${UNIQ}_filtered_merged.vcf.gz ;
}


[ -s ${UNIQ}_filtered_merged.vcf.gz ] || { echo -e "\e[1;31m [!] Compressed merged vcf file is empty or does not exist, exiting."; exit ;}

echo -e "\e[1;34m [%] Finished vcf file merging. \e[0m"

###################

#then make the Fasta files for each sample and put them in the corresponding directory and catenate them into one. Also rename the genomes in the fasta files so that it contains the sample name, otherwise they won't be distinguishable in subsequent analyses.

echo -e "\e[1;33m\n ------------ \n Starting Fasta file creation. \n ------------ \n\e[0m"

[ -s ${UNIQ}_filtered_merged.vcf.gz ] && echo -e "\e[1;35m[@] ${UNIQ}_filtered_merged.vcf.gz already exists\e[0m" || bgzip ${UNIQ}_filtered_merged.vcf

[ -s ${UNIQ}_filtered_merged.vcf.gz.csi ] && echo -e "\e[1;35m[@] ${UNIQ}_filtered_merged.vcf.gz already indexed\e[0m" || bcftools index ${UNIQ}_filtered_merged.vcf.gz 

for i in $(bcftools query -l ${UNIQ}_filtered_merged.vcf.gz); do 
    name=$(echo ${i} | cut -d "_" -f1);
    if [ -s ${MYPATH}/fasta_aln/${name}.fasta ]; then
	echo -e "\e[1;35m${MYPATH}/fasta_aln/${name}.fasta already exists.\e[0m"
    else
	echo -e "\e[1;33mMaking Fasta for ${i}\e[0m"; 
        bcftools consensus \
		 --fasta-ref $REFPATH \
		 --sample ${i}  \
		 ${UNIQ}_filtered_merged.vcf.gz | 
	    sed "s/^>/>${name} /" > $MYPATH/fasta_aln/${name}.fasta || { echo -e "\e[1;31mCannot create fasta files. Check MYPATH variable.\e[0m"; exit; }; 
    fi;
done

cd $MYPATH/fasta_aln

cat $REFPATH *.fasta > $UNIQ.aln

###################

echo -e "\e[1;34m [%] Finished Fasta file creation. Alignment file has been created. \e[0m"

#Load and run snp-sites to extract the SNP sites from the alignment file.

echo -e "\e[1;33m [%] Starting SNP_Sites. \e[0m"

#module load snp-sites/2.5.1

[ -s ${UNIQ}.snp_sites.aln ] && echo -e "\e[1;35m [@] snp-sites already completed.\e[0m" || snp-sites -mvp -o ${UNIQ} ${UNIQ}.aln
[ -s ${UNIQ}_fconst.aln ] && echo -e "\e[1;35m [@] Constant sites already calculated.\e[0m" || snp-sites -mvpC -o ${UNIQ}_fconst.aln ${UNIQ}.aln

echo -e "\e[1;34m [%] Finished Fasta file creation. Alignment files have been created. \e[0m"

#Move into the tree directory, copy the aligned SNPs file and load RAxML for tree building. 

echo -e "\e[1;33m [%] Starting Tree building with RAxML.\e[0m"

[ -f ../tree/${UNIQ}.aln ] && echo -e "\e[1;35m [@] ${UNIQ}.aln already copied.\e[0m" || cp ${UNIQ}.aln ../tree/
[ -f ../tree/${UNIQ}_fconst.aln ] && echo -e "\e[1;35m [@] ${UNIQ}_fconst.aln already copied.\e[0m" || cp ${UNIQ}_fconst.aln ../tree/
[ -f ../tree/${UNIQ}.phylip ] && echo -e "\e[1;35m [@] ${UNIQ}.phylip already copied.\e[0m" || cp ${UNIQ}.phylip ../tree/
[ -f ../tree/${UNIQ}.snp_sites.aln ] && echo -e "\e[1;35m [@] ${UNIQ}.snp_sites.aln already copied.\e[0m" || cp ${UNIQ}.snp_sites.aln ../tree/

cd ../tree
[ -d RAxML ] || mkdir RAxML 

if [ -s ${MYPATH}/tree/RAxML/RAxML_bestTree.${UNIQ}_SNP_Tree ]; then
    echo -e "\e[1;35m [@] RAxML SNP tree file already created at ${MYPATH}/tree/RAxML/RAxML_bestTree.${UNIQ}_SNP_Tree\e[0m";
else
    {
	raxmlHPC-PTHREADS-SSE3 -T ${THREADS} -f a -p 12345 -x 12345 -# 100 -m GTRCAT -s ${UNIQ}.snp_sites.aln -n ${UNIQ}_SNP_Tree -w ${MYPATH}/tree/RAxML \
	    || echo -e "\e[1;31m [!] RAxML did not run successfully. Check required file ${UNIQ}/snp_sites.aln is present in the tree directory. Alternatively, if AMBoP was cancelled prematurely, remove all tree files and run again.\e[0m"; }
fi


echo -e "\e[1;34m [%] Finished Tree building with RAxML. \n\e[0m";
echo -e "\e[1;36m [?] Final tree file is in file RAxML_bipartitionsBranchLabels.${UNIQ} \e[0m"

#########################
#Make tree with model predictions and constant sites with IQTree

echo -e "\e[1;33m [%] Starting Tree building with IQ-Tree.\e[0m"

[ -d IQTree ] || mkdir IQTree

if [ ! -f IQTree/${UNIQ}.treefile ] && [ -s ${UNIQ}_fconst.aln ]; then
    iqtree -nt AUTO -s ${UNIQ}.phylip -m MFP -bb 1000 -fconst $(cat ${UNIQ}_fconst.aln) -pre IQTree/${UNIQ};
elif [ ! -s ${UNIQ}_fconst.aln ]; then
    echo -e "\e[1;31m [!] ${UNIQ}_fconst.aln not available. IQTree will not run successfully without this file.\e[0m"
else 
    echo -e "\e[1;35m [@] IQTree files already present\e[0m"
fi

echo -e "\e[1;34m [%] Finished Tree building with IQ-Tree. \n\e[0m"
echo -e "\e[1;36m [?] Final tree file is in file ${UNIQ}.treefile \e[0m"

echo -e "\e[1;36m [?] iTOL annotation files to add colour to trees can be created automatically using a metadata file and iTol_range_annotation_maker.py in the misc_tools-* module. Visualisation of presence or absence of SNPs in functional genes can be done using a binary matrix annotation add onto the tree, for which the tool iTol_binary_annotation_maker.py exists in the misc_tools-* module.\e[0m"


##########################

#Run snpEff to look at SNP Effects. Do this on the merged vcf file, and receive three output files - a html, a gene file and a designated output file in VCF format. Then also run the script to return two files, one (all_interesting_pos.tsv) containing the positions of the variants, reference allele, alternate allele, the number of samples and list of sample names (simplified VCF) and another file (variants_in_functional_genes.csv) which contains those variant positions that fall within genes/coding regions, with all the information from the gff and eggnog annotations provided for each gene that the variants are is in.

echo -e "\e[1;33m [%] Getting effects and functional annotations of variants in coding regions.\e[0m"

cd ${MYPATH}/variants/functional

###This fix is required only for use with Mycobacterium bovis analysis:

zcat ${MYPATH}/variants/${UNIQ}_filtered_merged.vcf.gz | sed 's/LT708304.1/Mycobacterium_bovis_AF2122_97/' > ${MYPATH}/variants/${UNIQ}_filtered_merged.edited.vcf
[ -s ${UNIQ}_snpEff.out ] && echo -e "\e[1;35m [@] snpEff output file already exists in variants/functional. Check it is complete, or delete and rerun AMBoP.\e[0m" || snpEff ${SNPEFF_DB} ${MYPATH}/variants/${UNIQ}_filtered_merged.edited.vcf -formatEff > ${UNIQ}_snpEff.out


echo -e "\e[1;36m [?] Note: snpEff output can be found in ${UNIQ}_snpeff.out. This contains much more information about the resulting SNP Effects. See http://pcingola.github.io/SnpEff/se_inputoutput/#eff-field-vcf-output-files for output file format and information included. Only the first reported SNP effect is retained in subsequent functional output files.\e[0m"

if [ $(cat all_interesting_pos.tsv 2>/dev/null | wc -l) -gt 1 ] && [ $(cat variants_in_functional_genes.csv 2>/dev/null | wc -l) -gt 1 ]; then 
    echo -e "\e[1;35m [@] variants_in_functional_genes.csv and all_interesting_pos.tsv output files are already present, check they are complete or remove and rerun AMBoP.\e[0m";
else
    cat ${UNIQ}_snpEff.out  | ${AUX_TOOLS}/functional_variants.py ${REF_FUNC_ANNO};
fi

echo -e "\e[1;34m [%] Finished getting effects and functional annotations for variants in coding regions. \n\e[0m"  

echo -e "\e[1;33m [%] Creating sample statistics.\e[0m"

cd ${MYPATH}

for i in $(ls ${DATAPATH}/*${FORWARDPATTERN}*); do
    isolate=$(echo ${i} | awk -F "/" '{print $NF}' | sed  "s/_R1/;/" $NF | sed "s/_R2/;/" $NF  | cut -d ";" -f1);
    ${AUX_TOOLS}/read_stats.sh ${isolate} ${CONFIG_DIR}/$1;
done |
     sed '2,${/^#/d;}' > ${MYPATH}/final_files/read_stats.csv

echo -e "\e[1;34m [%] Finished creating sample statistics. \e[0m"  

echo -e "\e[1;33m [%] Entering clear up phase.\e[0m"
echo -e "\e[1;35m [@] You have specified to remove these directories: ${CLEARUP}\e[0m"

 
 
cd ${MYPATH}/final_files  
ln -s ${MYPATH}/variants/functional 2>/dev/null
ln -s ${MYPATH}/tree 2>/dev/null
ln -s ${MYPATH}/variants/${UNIQ}_filtered_merged.vcf.gz 2>/dev/null
ln -s ${MYPATH}/bams/bamfile_coverage.list 2>/dev/null

[[ ${CLEARUP} = "ALL" ]] && rm -rf ${MYPATH}/trimmed_reads ${MYPATH}/bams ${MYPATH}/passed_files ${MYPATH}/fasta_aln ${MYPATH}/variants ${MYPATH}/tree  
[[ ${CLEARUP} = *"TRIMMEDREADS"* ]] && rm -rf ${MYPATH}/trimmed_reads 
[[ ${CLEARUP} = *"BAMS"* ]] && rm -rf ${MYPATH}/bams 
[[ ${CLEARUP} = *"PASSEDFILES"* ]] && rm -rf ${MYPATH}/passed_files 
[[ ${CLEARUP} = *"FASTA"* ]] && rm -rf ${MYPATH}/fasta_aln
[[ ${CLEARUP} = *"VARIANTS"* ]] && rm -rf ${MYPATH}/variants  

echo -e "\e[1;34m [%] Finished clear up phase.\e[0m"
echo -e "\e[1;36m [?] Final files can be found here: ${MYPATH}/final_files \e[0m"
echo -e "\e[1;36m [?] AMBoP experiment ${UNIQ} Complete.\e[0m"


